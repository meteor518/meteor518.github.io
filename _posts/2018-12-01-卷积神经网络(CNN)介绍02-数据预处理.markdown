---
layout: post
title:  "卷积神经网络(CNN)介绍02-数据预处理"

---

# 数据预处理

输入网络之前通常会对图片进行一些预处理操作，例如：滤波去噪(均值滤波、中值滤波、高斯滤波等)，去均值，归一化，白化等操作。


### 标准化


需要消除样本不同属性具有不同量级时的影响：

1) 数量级的差异将导致量级较大的属性占据主导地位；

2) 数量级的差异将导致迭代收敛速度减慢；

3) 依赖于样本距离的算法对于数据的数量级非常敏感。

`min-max标准化（归一化）`

归一化为了让不同维度的数据具有相同的分布。对于每个属性，设minA和maxA分别为属性A的最小值和最大值，将A的一个原始值x通过min-max标准化映射成在区间[0,1]中的值x'，其公式为：新数据 = (原数据 - 最小值) / (最大值 - 最小值)。

`z-score标准化（规范化）`

基于原始数据的均值（mean）和标准差（standarddeviation）进行数据的标准化。将A的原始值x使用z-score标准化到x'。z-score标准化方法适用于属性A的最大值和最小值未知的情况，或有超出取值范围的离群数据的情况。新数据 = (原数据 - 均值) / 标准差

`去均值`也叫`中心化`

新数据= 原数据 - 均值。 数据有过大的均值，可能导致参数的梯度过大。去均值并没有消除像素之间的相对差异。(人们对于图像信息的摄取通常来自于像素间的相对色差，而不是像素值的高低。)



**标准化/归一化的原因：**

1. 归一化/标准化实质是一种*线性变换*，线性变换有很多良好的性质，这些性质决定了对数据改变后不会造成“失效”，反而能提高数据的表现，这些性质是归一化/标准化的前提。比如有一个很重要的性质：线性变换不会改变原始数
2. 在使用梯度下降的方法求解最优化问题时， 归一化/标准化后可以加快梯度下降的求解速度，即*提升模型的收敛速度*。
3. 无量纲化。
4. 避免数值问题： 太大的数会引发数值问题。避免异常值和极端值的影响(噪音)。

神经网络学习过程本质就是为了学习数据分布，一旦训练数据与测试数据的分布不同，那么网络的泛化能力也大大降低；另外一方面，一旦每批训练数据的分布各不相同(batch 梯度下降)，那么网络就要在每次迭代都去学习适应不同的分布，这样将会大大降低网络的训练速度，这也正是为什么我们需要对数据都要做一个归一化预处理的原因。


对于深度网络的训练是一个复杂的过程，只要网络的前面几层发生微小的改变，那么后面几层就会被累积放大下去。一旦网络某一层的输入数据的分布发生改变，那么这一层网络就需要去适应学习这个新的数据分布，所以如果训练过程中，训练数据的分布一直在发生变化，那么将会影响网络的训练速度。


### 白化

白化，又称漂白或者球化；是对原始数据x实现一种变换，变换成x_Whitened;使x_Whitened的协方差矩阵的为单位阵。

一般情况下，所获得的数据都具有相关性，所以通常都要求对数据进行初步的白化或球化处理，因为白化处理可*去除各观测信号之间的相关性*，从而简化了后续独立分量的提取过程，而且，通常情况下，数据进行白化处理与不对数据进行白化处理相比，算法的收敛性较好。


由于原始图像相邻像素值具有高度相关性，所以图像数据信息冗余，对于白化的作用的描述主要有两个方面：

1. 减少特征之间的相关性；
2. 特征具有相同的方差（协方差阵为1）

白化分为`PCA白化`、`ZCA白化`，实现原理见[网页](https://blog.csdn.net/lx_xin/article/details/81909038)

